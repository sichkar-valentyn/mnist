
<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="/mnist/assets/css/style.css?v=f5115139db52d20db14e8e20cfd470512e23b4b7">
    <link rel="icon" type="image/x-icon" href="/mnist/images/favicon.ico" />
	  
<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>MNIST Digits Classification with numpy only  - Valentyn Sichkar</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="MNIST Digits Classification with numpy only" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="MNIST Digits Classification with numpy only" />
<meta property="og:description" content="MNIST Digits Classification with numpy only" />
<link rel="canonical" href="https://sichkar-valentyn.github.io/mnist/" />
<meta property="og:url" content="https://sichkar-valentyn.github.io/mnist/" />
<meta property="og:site_name" content="mnist" />
<script type="application/ld+json">
{"@type":"WebSite","headline":"MNIST Digits Classification with numpy only","url":"https://sichkar-valentyn.github.io/mnist/","name":"mnist","description":"MNIST Digits Classification with numpy only","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">          
          <a id="forkme_banner" href="https://github.com/sichkar-valentyn/Neural_Networks_for_Computer_Vision">View on GitHub</a>
          <h1 id="project_title">MNIST</h1>
          <h2 id="project_tagline">MNIST Digits Classification with numpy only</h2>
		
	  <a href="https://sichkar-valentyn.github.io">by Valentyn Sichkar</a>
          &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://ifmo.academia.edu/ValentynSichkar" target="_blank">Academia.edu</a>
          &nbsp;&nbsp;&nbsp;&nbsp;<a href="https://www.youtube.com/channel/UCHlzRR0y54SLbcHwLzrUcfw" target="_blank">YouTube</a>          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1 id="mnist-digits-classification-with-numpy-only">MNIST Digits Classification with <code class="highlighter-rouge">numpy</code> only</h1>
<p>Example on Digits Classification with the help of MNIST dataset of handwritten digits and Convolutional Neural Network.
<br /><a href="https://doi.org/10.5281/zenodo.1317904"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.1317904.svg" alt="DOI" /></a></p>

<h2 id="test-online-here">Test online <a href="https://valentynsichkar.name/mnist.html">here</a></h2>

<h2 id="explore-course">Course:</h2>
<ul>
  <li>Explore course <strong>"Convolutional Neural Networks for Image Classification"</strong> here: <a href="https://stepik.org/course/53801/promo" target=_blank>https://stepik.org/course/53801/promo</a></li>
</ul>

<h2 id="content">Content</h2>
<p>Short description of the content. Full codes you can find inside the course by link above:</p>

<ul>
  <li><a href="#mnist-digits-classification-with-numpy-library-only">MNIST Digits Classification with <code class="highlighter-rouge">numpy</code> only</a>
    <ul>
      <li><a href="#loading-mnist-dataset">Loading MNIST dataset</a></li>
      <li><a href="#plotting-examples-of-digits-from-mnist-dataset">Plotting examples of digits from MNIST dataset</a></li>
      <li><a href="#preprocessing-loaded-mnist-dataset">Preprocessing loaded MNIST dataset</a></li>
      <li><a href="#saving-and-loading-serialized-models">Saving and Loading serialized models</a></li>
      <li><a href="#functions-for-dealing-with-cnn-layers">Functions for dealing with CNN layers</a>
        <ul>
          <li>Naive Forward Pass for Convolutional layer</li>
          <li>Naive Backward Pass for Convolutional layer</li>
          <li>Naive Forward Pass for Max Pooling layer</li>
          <li>Naive Backward Pass for Max Pooling layer</li>
          <li>Forward Pass for Affine layer</li>
          <li>Backward Pass for Affine layer</li>
          <li>Forward Pass for ReLU layer</li>
          <li>Backward Pass for ReLU layer</li>
          <li>Softmax Classification loss</li>
        </ul>
      </li>
      <li><a href="#creating-classifier-model-of-cnn">Creating Classifier - model of CNN</a>
        <ul>
          <li>Initializing new Network</li>
          <li>Evaluating loss for training ConvNet1</li>
          <li>Calculating scores for predicting ConvNet1</li>
        </ul>
      </li>
      <li><a href="#optimization-functions">Functions for Optimization</a>
        <ul>
          <li><a href="#vanilla-sgd">Vanilla SGD</a></li>
        </ul>
      </li>
      <li><a href="#creating-solver-class">Creating Solver Class</a>
        <ul>
          <li>_Reset</li>
          <li>_Step</li>
          <li>Checking Accuracy</li>
          <li>Train</li>
        </ul>
      </li>
      <li><a href="#overfitting-small-data">Overfitting Small Data</a></li>
      <li><a href="#training-results">Training Results</a></li>
      <li><a href="#full-codes">Full Codes</a></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="mnist-digits-classification-with-numpy-only-1"><a id="mnist-digits-classification-with-numpy-library-only">MNIST Digits Classification with <code class="highlighter-rouge">numpy</code> only</a></h3>
<p>In this example we’ll test CNN for Digits Classification with the help of MNIST dataset.
<br />Following standard and most common parameters can be used and tested:</p>

<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Weights Initialization</td>
      <td>HE Normal</td>
    </tr>
    <tr>
      <td>Weights Update Policy</td>
      <td>Vanilla SGD, Momentum SGD, RMSProp, Adam</td>
    </tr>
    <tr>
      <td>Activation Functions</td>
      <td>ReLU, Sigmoid</td>
    </tr>
    <tr>
      <td>Regularization</td>
      <td>L2, Dropout</td>
    </tr>
    <tr>
      <td>Pooling</td>
      <td>Max, Average</td>
    </tr>
    <tr>
      <td>Loss Functions</td>
      <td>Softmax, SVM</td>
    </tr>
  </tbody>
</table>

<p><br />Contractions:</p>
<ul>
  <li><strong>Vanilla SGD</strong> - Vanilla Stochastic Gradient Descent</li>
  <li><strong>Momentum SGD</strong> - Stochastic Gradient Descent with Momentum</li>
  <li><strong>RMSProp</strong> - Root Mean Square Propagation</li>
  <li><strong>Adam</strong> - Adaptive Moment Estimation</li>
  <li><strong>SVM</strong> - Support Vector Machine</li>
</ul>

<p><br /><strong>For current example</strong> following architecture will be used:
<br /><code class="highlighter-rouge">Input</code> –&gt; <code class="highlighter-rouge">Conv</code> –&gt; <code class="highlighter-rouge">ReLU</code> –&gt; <code class="highlighter-rouge">Pool</code> –&gt; <code class="highlighter-rouge">Affine</code> –&gt; <code class="highlighter-rouge">ReLU</code> –&gt; <code class="highlighter-rouge">Affine</code> –&gt; <code class="highlighter-rouge">Softmax</code></p>

<p><br /><strong>For current example</strong> following parameters will be used:</p>

<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Weights Initialization</td>
      <td><code class="highlighter-rouge">HE Normal</code></td>
    </tr>
    <tr>
      <td>Weights Update Policy</td>
      <td><code class="highlighter-rouge">Vanilla SGD</code></td>
    </tr>
    <tr>
      <td>Activation Functions</td>
      <td><code class="highlighter-rouge">ReLU</code></td>
    </tr>
    <tr>
      <td>Regularization</td>
      <td><code class="highlighter-rouge">L2</code></td>
    </tr>
    <tr>
      <td>Pooling</td>
      <td><code class="highlighter-rouge">Max</code></td>
    </tr>
    <tr>
      <td>Loss Functions</td>
      <td><code class="highlighter-rouge">Softmax</code></td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="loading-mnist-dataset"><a id="loading-mnist-dataset">Loading MNIST dataset</a></h3>
<p>After downloading files from official resource, there has to be following files:</p>
<ul>
  <li>train-images-idx3-ubyte.gz</li>
  <li>train-labels-idx1-ubyte.gz</li>
  <li>t10k-images-idx3-ubyte.gz</li>
  <li>t10k-labels-idx1-ubyte.gz</li>
</ul>

<p><br /></p>

<h3 id="plotting-examples-of-digits-from-mnist-dataset"><a id="plotting-examples-of-digits-from-mnist-dataset">Plotting examples of digits from MNIST dataset</a></h3>
<p>After dataset was load, it is possible to show examples of training images.

<p>Result can be seen on the image below.</p>

<p><img src="images/MNIST_examples.png" alt="MNIST_examples" /></p>

<p><br /></p>

<h3 id="preprocessing-loaded-mnist-dataset"><a id="preprocessing-loaded-mnist-dataset">Preprocessing loaded MNIST dataset</a></h3>
<p>Next, creating function for preprocessing MNIST dataset for further use in classifier.</p>
<ul>
  <li>Normalizing data by <code class="highlighter-rouge">dividing / 255.0</code> (!) - up to researcher</li>
  <li>Normalizing data by <code class="highlighter-rouge">subtracting mean image</code> and <code class="highlighter-rouge">dividing by standard deviation</code> (!) - up to researcher</li>
  <li>Transposing every dataset to make channels come first</li>
  <li>Returning result as dictionary</li>
</ul>

<p>As a result there will be following:</p>
<ul>
  <li><code class="highlighter-rouge">x_train: (59000, 1, 28, 28)</code></li>
  <li><code class="highlighter-rouge">y_train: (59000,)</code></li>
  <li><code class="highlighter-rouge">x_validation: (1000, 1, 28, 28)</code></li>
  <li><code class="highlighter-rouge">y_validation: (1000,)</code></li>
  <li><code class="highlighter-rouge">x_test: (1000, 1, 28, 28)</code></li>
  <li><code class="highlighter-rouge">y_test: (1000,)</code></li>
</ul>

<p><br /></p>

<h3 id="saving-and-loading-serialized-models"><a id="saving-and-loading-serialized-models">Saving and Loading serialized models</a></h3>
<p>Saving loaded and preprocessed data into ‘pickle’ file.

<p><br /></p>

<h3 id="functions-for-dealing-with-cnn-layers"><a id="functions-for-dealing-with-cnn-layers">Functions for dealing with CNN layers</a></h3>
<p>Creating functions for CNN layers:</p>
<ul>
  <li>Naive Forward Pass for Convolutional layer</li>
  <li>Naive Backward Pass for Convolutional layer</li>
  <li>Naive Forward Pass for Max Pooling layer</li>
  <li>Naive Backward Pass for Max Pooling layer</li>
  <li>Forward Pass for Affine layer</li>
  <li>Backward Pass for Affine layer</li>
  <li>Forward Pass for ReLU layer</li>
  <li>Backward Pass for ReLU layer</li>
  <li>Softmax Classification loss</li>
</ul>

<p><br /></p>

<h3 id="creating-classifier---model-of-cnn"><a id="creating-classifier-model-of-cnn">Creating Classifier - model of CNN</a></h3>
<p>Creating model of CNN Classifier:</p>
<ul>
  <li>Creating class for ConvNet1</li>
  <li>Initializing new Network</li>
  <li>Evaluating loss for training ConvNet1</li>
  <li>Calculating scores for predicting ConvNet1</li>
</ul>

<p><br /></p>

<h3 id="defining-functions-for-optimization"><a id="optimization-functions">Defining Functions for Optimization</a></h3>
<p>Using different types of optimization rules to update parameters of the Model.</p>

<h4 id="vanilla-sgd-updating-method"><a id="vanilla-sgd">Vanilla SGD updating method</a></h4>
<p>Rule for updating parameters is as following:</p>

<p><img src="images/vanilla_sgd.png" alt="Vanilla SGD" /></p>

<p><br /></p>

<h3 id="creating-solver-class"><a id="creating-solver-class">Creating Solver Class</a></h3>
<p>Creating Solver class for training classification models and for predicting:</p>
<ul>
  <li>Creating and Initializing class for Solver</li>
  <li>Creating ‘reset’ function for defining variables for optimization</li>
  <li>Creating function ‘step’ for making single gradient update</li>
  <li>Creating function for checking accuracy of the model on the current provided data</li>
  <li>Creating function for training the model</li>
</ul>

<p><br /></p>

<h3 id="overfitting-small-data"><a id="overfitting-small-data">Overfitting Small Data</a></h3>
<p><img src="images/overfitting_small_data_model_1_mnist.png" alt="Overfitting Small Data" /></p>

<p><br /></p>

<h3 id="training-results"><a id="training-results">Training Results</a></h3>
<p>Training process of Model #1 with 12 000 iterations is shown on the figure below:</p>

<p><img src="images/training_model_1_mnist.png" alt="Training Model 1" /></p>

<p>Initialized Filters and Trained Filters for ConvNet Layer is shown on the figure below:</p>

<p><img src="images/filters_mnist.png" alt="Filters Cifar10" /></p>

<p>Training process for Filters of ConvNet Layer is shown on the figure below:</p>

<p><img src="images/mnist_filters_training.gif" alt="Training Filters Cifar10" /></p>

<p><br /></p>

<h3 id="mit-license">MIT License</h3>
<h3 id="copyright-c-2018-valentyn-n-sichkar">Copyright (c) 2018 Valentyn N Sichkar</h3>
<h3 id="githubcomsichkar-valentyn">github.com/sichkar-valentyn</h3>
<h3 id="reference-to">Reference to:</h3>
<p>Valentyn N Sichkar. Neural Networks for computer vision in autonomous vehicles and robotics // GitHub platform. DOI: 10.5281/zenodo.1317904</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        
        <p class="copyright">"MNIST" maintained by <a href="https://github.com/sichkar-valentyn">Valentyn Sichkar</a></p>
      </footer>
    </div>

    
  </body>
</html>
